package com.ericsson.eniq.etl.bcd;

import java.io.IOException;
import java.text.SimpleDateFormat;
import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.HashMap;
import java.util.LinkedHashMap;
import java.util.List;
import java.util.StringTokenizer;


import org.xml.sax.Attributes;
import org.xml.sax.SAXException;
import org.xml.sax.helpers.DefaultHandler;

import com.distocraft.dc5000.etl.parser.Main;
import com.distocraft.dc5000.etl.parser.MeasurementFile;
import com.distocraft.dc5000.etl.parser.Parser;
import com.distocraft.dc5000.etl.parser.SourceFile;
import com.distocraft.dc5000.repository.cache.DFormat;
import com.distocraft.dc5000.repository.cache.DItem;
import com.distocraft.dc5000.repository.cache.DataFormatCache;
//import com.sybase.jdbc3.tds.DataFormat;

import java.util.Map.Entry;
import java.util.logging.Level;
import java.util.logging.Logger;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.regex.PatternSyntaxException;

import javax.xml.parsers.ParserConfigurationException;
import javax.xml.parsers.SAXParser;
import javax.xml.parsers.SAXParserFactory;

/**
 * Parses a topology (CM data) xml generated by OSS-RC, of format bulkCmConfigDataFile. The <br>
 * <table border="1" width="100%" cellpadding="3" cellspacing="0">
 * <tr bgcolor="#CCCCFF" class="TableHeasingColor">
 * <td colspan="3"><font size="+2"><b>Parameter Summary</b></font></td>
 * </tr>
 * <tr>
 * <td><b>Key Name</b ></td>
 * <td><b>Description</b></td>
 * <td><b>Default</b></td>
 * </tr>
 * <tr>
 * <td>BCDParser.removeRootMoR</td>
 * <td>Determinates whether the _R should be removed from FDN and from Managed
 * Object references.</td>
 * <td>true</td>
 * </tr>
 * <tr>
 * <td>BCDParser.removeVsData</td>
 * <td>Determinates whether the vsData should be removed from FDN and from
 * Managed Object references.</td>
 * <td>true</td>
 * </tr>
 * <tr>
 * <td>BCDParser.sequenceSeparator</td>
 * <td>Defines the value that is used to separate sequence lists when they're
 * are loaded to non-vector table.</td>
 * <td>;</td>
 * </tr>
 * </table>
 * <br>
 * <br>
 * 
 * <table border="1" width="100%" cellpadding="3" cellspacing="0">
 * <tr bgcolor="#CCCCFF" class="TableHeasingColor">
 * <td colspan="4"><font size="+2"><b>Added DataColumns</b></font></td>
 * </tr>
 * <tr>
 * <td><b>Column name</b></td>
 * <td><b>Description</b></td>
 * <td><b>Depends on Parameter(s)</b></td>
 * <td><b>Default</b></td>
 * </tr>
 * <tr>
 * <td>AOM</td>
 * <td>Contains the AOM Number. Taken with Interface Transformation Pattern from filename.</td>
 * <td>
 * <div> BCDParser.aomIdentifier </div> <div> BCDParser.aomPattern </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>CU</td>
 * <td>Contains the OSS CU Number. Taken with Interface Transformation Pattern from filename.</td>
 * <td>
 * <div> BCDParser.cuIdentifier </div> <div> BCDParser.cuPattern </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DATETIME_ID</td>
 * <td>Contains the Datetime ID. Taken from filename.</td>
 * <td>BCDParser.dateTimeIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DIRNAME</td>
 * <td>Contains the full path to the inputfile.</td>
 * <td>BCDParser.dirnameIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_RELEASE</td>
 * <td>Contains the OSS Release. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>
 * <div> BCDParser.releaseIdentifier </div> <div> BCDParser.releasePattern
 * </div></td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_SOURCE</td>
 * <td>Contains the DC Source value. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>BCDParser.sourceIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DC_TIMEZONE</td>
 * <td>Contains the Timezone value. Taken from filename.</td>
 * <td>BCDParser.timezoneIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>DCVECTOR_INDEX</td>
 * <td>Contains the range index of sequence (e.g. VECTOR) measurements.</td>
 * <td>BCDParser.sequenceIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * 
 * <tr>
 * <td>ELEMENT</td>
 * <td>Contains the name of the Element. Only applicable for Measurement's that
 * have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>ELEMENTPARENT</td>
 * <td>Contains the parent of the Element. Only applicable for Measurement's
 * that have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>ELEMENTTYPE</td>
 * <td>Contains the type of the Element. Only applicable for Measurement's that
 * have ManagedElement in MOID.</td>
 * <td>&nbsp;</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * 
 * 
 * <tr>
 * <td>FDN</td>
 * <td>Contains the Fully Distinguished Name of the Managed Object.</td>
 * <td>BCDParser.fdnIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>FILENAME</td>
 * <td>Contains the filename of the inputfile.</td>
 * <td>BCDParser.filenameIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>JVM_TIMEZONE</td>
 * <td>Contains the JVM timezone (example. +0200)</td>
 * <td>BCDParser.jvmTimezoneIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>MOID</td>
 * <td>Contains the Managed Object Identifier part from FDN.</td>
 * <td>BCDParser.moidIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * <tr>
 * <td>OSS_ID</td>
 * <td>Contains the OSS Identifier. Taken with Interface Transformation Pattern
 * from filename.</td>
 * <td>
 * <div> BCDParser.ossIdPattern </div> <div> BCDParser.ossIdIdentifier </div></td>
 * <td>&nbsp;</td>
 * </tr>
 *<tr>
 * <td>PERIOD_DURATION</td>
 * <td>Contains the Period Duration. Fixed value.</td>
 * <td>BCDParser.periodDurationIdentifier</td>
 * <td>1440</td>
 * </tr>
 * <tr>
 * <td>SN</td>
 * <td>Contains the Sender Name part from FDN.</td>
 * <td>BCDParser.snIdentifier</td>
 * <td>&nbsp;</td>
 * </tr>
 * 
 * <tr>
 * <td>TIMELEVEL</td>
 * <td>Contains the Timelevel. Fixed value.</td>
 * <td>BCDParser.timelevelIdentifier</td>
 * <td>24H</td>
 * </tr>
 * 
 * </table>
 * <h1>Example</h1> <div> 1. Inputfiles are located in
 * /eniq/data/pmdata/eniq_oss_1/foo/1<br/>
 * 2. BCDParser.ossIdentifier is set to: FooKey<br/>
 * 3. BCDParser.ossPattern is set to: .+//(.+)//.+//.+ </div> <br/>
 * <br/>
 * <div>This would result the parser to produce a key called FooKey with value
 * of the eniq_oss_1 </div> <br/>
 * <br/>
 * 
 * @author Jouni Makinen (lmfjou)
 * 
 */
public class BCDParser extends DefaultHandler implements Parser {
	/*
	 * Nodetypes
	 */
	final String OSSRC = "OSSRC";
	final String RNC = "RNC";
	final String TDRNC = "TDRNC";
	final String TDRBS = "TDRBS";
	final String RBS = "RBS";
	//EDEAMAI - RegExp patterns to be matched against FDN of MOs. Groups 1 and group 2 (marked by brackets) are for determination of PARENTELEMENT and ELEMENT keys respectively.
	final String rncPattern = "SubNetwork=(.+),SubNetwork=.+,MeContext=(.+),ManagedElement=.+";
	final String rbsPattern = "SubNetwork=.+,SubNetwork=(.+),MeContext=(.+),ManagedElement=.+";
	final String otherPattern = "SubNetwork=(.+),MeContext=(.+),ManagedElement=.+"; //EDEAMAI - default for RXI and OSSRC, and any other node type for which there is no regExp configured in interface
	HashMap<String, Pattern> elementFDNMap = new HashMap<String, Pattern>();
	String elementType = OSSRC;
	String parentNode = null;
	String elementNode = null;

	/*
	 * Interface parameters
	 */
	boolean removeRootMoR;
	boolean removeVsData;
	String fdnIdentifier;
	String snIdentifier;
	String moidIdentifier;
	String structIdentifier;
	String sequenceSeparator;
	String sequenceIdentifier;
	String aomIdentifier;
	String cuIdentifier;
	String releaseIdentifier;
	String dateTimeIdentifier;
	String timezoneIdentifier;
	String timelevelIdentifier;
	String periodDurationIdentifier;
	String ossIdIdentifier;
	String sourceIdentifier;
	String filenameIdentifier;
	String jvmTimezoneIdentifier;
	String dirnameIdentifier;
	/*
	 * Interface filelookup parameters
	 */
	String aomPattern;
	String cuPattern;
	String releasePattern;
	String hostnamePattern;  //Never used
	String datetimeIdPattern;
	String ossIdPattern;
	String timeZonePattern;
	String aom;
	String cu;
	String release;
	String hostname;
	String datetimeId;
	String timeZone;
	String ossId;
	String timelevel;
	String periodDuration;
	ArrayList<String> elementTypesSup = new ArrayList<String>(); //EDEAMAI - Comma separated list os supported node types.
	String elementTypesFDN; //EDEAMAI - Comma separated list of nodes with FDN pattern provided.
	/*
	 * MO Parameters
	 */
	Fdn fdn = null;
	String moId = null;
	String moClass = null;
	String parentMoClass = null;
	String parentMoId = null;
	String vsDataClass = "";
	int fdnDepth = 0;
	int attributeDepth = 0;
	int sequenceIndex = 0;
	/*
	 * Handling parameters
	 */
	boolean collect = false;
	boolean isStruct = false;
	/*
	 * XML Tags
	 */
	String elementParent = null;
	String elementStart = null;
	String elementEnd = null;
	String elementStruct = null;
	StringBuilder characters = null;
	/*
	 * DataMap which contains attributes
	 */
	HashMap<String, String> dataMap = null;
	HashMap<String, String> docDataMap = null;
	LinkedHashMap<String, HashMap<String, String>> vectorMap = null;

	/*
	 * Document variables
	 */
	long start;
	long stop;
	/*
	 * Parser parameters
	 */
	private static final String JVM_TIMEZONE = new SimpleDateFormat("Z").format(new Date());
	HashMap<String, MeasurementFile> openFiles;
	HashMap<String, List<String>> vectorListSet;
	private Logger logger;
	private Main mainParser;
	private String techPack;
	private String setType;
	private String setName;
	private int status = 0;
	private String workerName;
	private SourceFile sourceFile;

	/**
	 * Initilizes the parameters needed for parsing
	 * 
	 */
	public void startDocument() throws SAXException {
		start = Calendar.getInstance().getTimeInMillis();
		logger.log(Level.FINEST, "Parser entering startDocument()....");
	}

	/**
	 * Lookups variables from filename
	 * 
	 * @param name
	 *            of the input file
	 * @param pattern
	 *            the pattern to lookup from the filename
	 * @return result returns the group(1) of result, or null
	 */
	private String transformFileVariables(String transformation, String filename, String pattern) {
		String result = null;
		try {
			Pattern p = Pattern.compile(pattern);
			Matcher m = p.matcher(filename);
			if (m.matches()) {
				result = m.group(1);
			}
		} catch (PatternSyntaxException e) {
			logger.log(Level.SEVERE, "Error performing transformFileVariables for BCDParser." + transformation, e);
		}
		return result;
	}

	/**
	 * Writes the parsed keys to the MeasurementFile
	 * 
	 * @param String
	 *            mo Name of the ManagedObject that is being written
	 * @param String
	 *            id The identifier of the ManagedObject that is being written
	 */
	private void writeData(String mo, String id) {
		try {

			/*
			 * Get the MeasurementFiles for ManagedObject Class
			 */
			MeasurementFile dataFile = getMFile(mo);
			MeasurementFile vectorFile = getMFile(mo + "_V");
			logger.log(Level.FINE, "Trying to write MO " + mo + "=" + id + " to MeasurementFile.");
			/*
			 * If we have a MeasurementFile, append parameters, otherwise don't
			 * do anything
			 */
			if (dataFile != null) {
				/*
				 * Write regular MO's
				 */
				if (!mo.equals("bulkCmConfigDataFile")) {
					/*
					 * Add the common keys to the measurement file
					 */
					dataMap.put(filenameIdentifier, sourceFile.getName());
					dataMap.put(jvmTimezoneIdentifier, JVM_TIMEZONE);
					dataMap.put(dirnameIdentifier, sourceFile.getDir());
					dataMap.put(fdnIdentifier, fdn.getFdn());
					dataMap.put(snIdentifier, fdn.getSn());
					dataMap.put(moidIdentifier, fdn.getMoid());
					dataMap.put(aomIdentifier, aom);
					dataMap.put(cuIdentifier, cu);
					dataMap.put(releaseIdentifier, release);
					dataMap.put(sourceIdentifier, hostname);
					dataMap.put(dateTimeIdentifier, datetimeId);
					dataMap.put(timezoneIdentifier, timeZone);
					dataMap.put(timelevelIdentifier, timelevel);
					dataMap.put(periodDurationIdentifier, periodDuration);
					dataMap.put(ossIdIdentifier, ossId);
					dataMap.put(mo + "Id", id);
					/*
					 * Add the DataMap to the measurement file and save the file
					 */
					dataFile.addData(dataMap);
					/*
					 * Add Element Data types to map
					 */
					final HashMap<String, String> elementDataMap = getElementData();
					if (!elementDataMap.isEmpty()) {
						dataFile.addData(elementDataMap);
					}
					dataFile.saveData();
				} else {
					/*
					 * Write bulkCmConfigDataFile
					 */
					docDataMap.put(filenameIdentifier, sourceFile.getName());
					docDataMap.put(jvmTimezoneIdentifier, JVM_TIMEZONE);
					docDataMap.put(dirnameIdentifier, sourceFile.getDir());
					docDataMap.put(aomIdentifier, aom);
					docDataMap.put(cuIdentifier, cu);
					docDataMap.put(releaseIdentifier, release);
					docDataMap.put(sourceIdentifier, hostname);
					docDataMap.put(dateTimeIdentifier, datetimeId);
					docDataMap.put(timezoneIdentifier, timeZone);
					docDataMap.put(timelevelIdentifier, timelevel);
					docDataMap.put(periodDurationIdentifier, periodDuration);
					docDataMap.put(ossIdIdentifier, ossId);
					dataFile.addData(docDataMap);
					dataFile.saveData();
					docDataMap.clear();
				}
			} else {
				logger.log(Level.WARNING, "MeasurementFile is [null] for mo " + mo + "!");
			}
			/*
			 * If we have a VectorFile, we will write
			 */
			if (vectorFile != null) {
			  
			  
			  
				/*
				 * Add the common Keys from "normal" measurementFile to
				 * vectorMeasurement, so we can get the
				 * vsDataFormatVersion,DATETIME_ID etc etc and the VECTOR
				 * counters that did have 0 or 1 values into VECTOR Measurement
				 */
				vectorFile.addData(dataMap);
				String vsDataFormatVersion = dataMap.get("vsDataFormatVersion");

				checkVectors(mo + "_V", dataMap);
				/*
				 * Iterate through VECTOR measurements
				 */
				
				for (Entry<String, HashMap<String, String>> entry : vectorMap.entrySet()) {
					String index = entry.getKey();
					/*
					 * Add the common keys to the vector file
					 */
					vectorFile
							.addData(filenameIdentifier, sourceFile.getName());
					vectorFile.addData(jvmTimezoneIdentifier, JVM_TIMEZONE);
					vectorFile.addData(dirnameIdentifier, sourceFile.getDir());
					vectorFile.addData(fdnIdentifier, fdn.getFdn());
					vectorFile.addData(snIdentifier, fdn.getSn());
					vectorFile.addData(moidIdentifier, fdn.getMoid());
					vectorFile.addData(aomIdentifier, aom);
					vectorFile.addData(cuIdentifier, cu);
					vectorFile.addData(releaseIdentifier, release);
					vectorFile.addData(sourceIdentifier, hostname);
					vectorFile.addData(dateTimeIdentifier, datetimeId);
					vectorFile.addData(timezoneIdentifier, timeZone);
					vectorFile.addData(timelevelIdentifier, timelevel);
					vectorFile.addData(periodDurationIdentifier, periodDuration);
					vectorFile.addData(ossIdIdentifier, ossId);
					vectorFile.addData(mo + "Id", id);
					vectorFile.addData(sequenceIdentifier, index);
					vectorFile.addData(entry.getValue());
					if (vsDataFormatVersion != null) {
						vectorFile.addData("vsDataFormatVersion", vsDataFormatVersion);
					}
					/*
					 * Add Element Data types to map
					 */
					final HashMap<String, String> elementDataMap = getElementData();
					if (!elementDataMap.isEmpty()) {
						vectorFile.addData(elementDataMap);
					}
					vectorFile.saveData();
				}

			} else {
				logger.log(Level.WARNING, "VectorFile is [null] for mo " + mo + "!");
			}

		} catch (Exception e) {
			logger.log(Level.SEVERE, "Exception while creating VectorFile for MO " + mo + "!", e);
		} finally {
			/*
			 * Once data is written, reset the DataMaps
			 */
			dataMap.clear();
			vectorMap.clear();
		}
	}

	private void checkVectors(String mo, HashMap<String, String> dataMap) {
    if (this.vectorListSet == null || this.vectorListSet.isEmpty()){
      return;
    }
    if (vectorMap == null){
      return;
    }
    
    List<String>vectorNames = vectorListSet.get(mo);
    if (vectorNames == null){
      return;
    }
    
    for (String vn : vectorNames){
      String cntrVal = dataMap.get(vn);
      if (cntrVal == null){
        continue;
      }
      
      HashMap<String, String> valueHolder = vectorMap.get("0");
      if (valueHolder == null){
        valueHolder = new HashMap<String, String> ();      
        vectorMap.put("0", valueHolder);
      }
      if (valueHolder.get(vn) == null) {
        valueHolder.put(vn, cntrVal);
      }
    }      
  }

  /**
	 * Closes all open MeasurementFiles and finishes parsing
	 * 
	 */
	public void endDocument() throws SAXException {
		logger.log(Level.FINEST, "Parser entering endDocument()....");
		stop = Calendar.getInstance().getTimeInMillis();
		for (String file : openFiles.keySet()) {
			logger.log(Level.FINEST, "Trying to close MeasurementFile " + file);
			MeasurementFile mFile = openFiles.get(file);
			try {
				mFile.close();
			} catch (Exception e) {
				logger.log(Level.SEVERE, "Unable to close MeasurementFile " + file + "!", e);
			}
		}
		logger.log(Level.INFO, "Parsing of file took " + (stop - start) / 1000 + " seconds in total.");

	}

	/**
	 * Collects the ManagedObject Id's and starts collection of attributes
	 */
	public void startElement(String namespaceURI, String localName, String qName, Attributes attrs) throws SAXException {
		/*
		 * Save the start tag for sequence handling Save the struct tag, in case
		 * the parameter is going to be StructRef
		 */
		elementParent = elementStart;
		elementStart = qName;
		/*
		 * We dont want to handle the header of the document, and we only
		 * execute this if we have id
		 */
		if ((!namespaceURI.equals("configData.xsd") || !namespaceURI.endsWith("#configData")) && attrs.getValue("id") != null) {
			/*
			 * Get the ID and the MO Class
			 */
			moId = attrs.getValue("id");
			moClass = qName.split(":")[1];
			fdnDepth++;
			/*
			 * We will initialize special cases afterwards if needed (internal
			 * mo + external mo will be handled as a same object. Standalone
			 * vsDataContainer will be initialized separately once we know the
			 * value of the tag vsDataType.
			 */
			if ((!qName.equals("xn:VsDataContainer") && !qName.equals("in:InventoryUnit"))) {
				/*
				 * If we have a new tag starting, and it's not a
				 * VsDataContainer, it can be written to the file, since it
				 * won't have a parent tag pending
				 */
				if (!dataMap.isEmpty()){ 
						if (elementTypesSup.isEmpty() || elementTypesSup.contains(elementType)) {
							//EDEAMAI - only write to file if the node type of this data is supported.
							writeData(parentMoClass, parentMoId);
						} else {
							//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
							dataMap.clear();
							vectorMap.clear();
						}
				}
				/*
				 * Handle the FDN
				 */
				fdn.handle(moClass + "=" + moId, fdnDepth);
				logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
				/*
				 * Store the previous MO, so we can use it to make the
				 * comparison whether the VsDataContainer following the MO
				 * container should be appended as same measurement type
				 */
				parentMoId = moId;
				parentMoClass = moClass;
			}
		} else {
			for (int i = 0; i < attrs.getLength(); i++) {
				docDataMap.put(attrs.getLocalName(i), attrs.getValue(i));
			}
		}
		/*
		 * Everytime we read an attribute, we need to mark down the depth. This
		 * is then used to check, whether the MO is a StructRef (e.g. level==
		 * 2), or just a plain attribute (level == 1)
		 */
		if (collect) {
			attributeDepth++;
		}

		/*
		 * We found attributes tag, so MO has attributes. Setting the collection
		 * flag to true
		 */
		if (qName.endsWith(":attributes")) {
			collect = true;
		}
	}

	private HashMap<String, String> getElementData() {
		final HashMap<String, String> tmpMap = new HashMap<String, String>();
		/*
		 * Handle the ELEMENTTYPE,NE and NEPARENT before writing
		 */
		//EDEAMAI - Check if there is a pre-compiled pattern for this type of node:
		Pattern p = elementFDNMap.get(elementType);
		if (null==p){
			p=elementFDNMap.get("other"); //EDEAMAI - Let us hope in future there will never be a node type called "other".
		}
		Matcher m = p.matcher(fdn.getFdn()); //EDEAMAI - Match regExp against FDN
		if (m.matches()) {
			tmpMap.put("ELEMENTTYPE", elementType);
			//EDEAMAI - ELEMENTPARENT and ELEMENT keys mapped to group 1 and group1 values respectively:
			tmpMap.put("ELEMENTPARENT", m.group(1));
			tmpMap.put("ELEMENT", m.group(2));
		} else {
			logger.finest("For "+fdn.getFdn()+" (of element type "+elementType+") could not get ELEMENT and ELEMENTPARENT using pattern "+p.pattern());
		}
		return tmpMap;
	}

	/**
	 * Stops collection of attributes and writes them to file
	 */
	public void endElement(String namespaceURI, String localName, String qName) throws SAXException {
		/*
		 * Save the end tag for sequence handling
		 */
		elementEnd = qName;
		/*
		 * Handle the elementType tag
		 */
		if (qName.equals("xn:managedElementType")) {
			elementType = characters.toString();
		}
		/*
		 * Reset the element Type once we have read the whole ManagedElement XML
		 * Element
		 */
		if (qName.equals("xn:ManagedElement")) {
			elementType = OSSRC;
		}

		/*
		 * We dont want to handle the header of the document, and we only
		 * execute this if we collect data
		 */

		if ((!namespaceURI.equals("configData.xsd") || !namespaceURI.endsWith("#configData")) && collect) {
			/*
			 * We have an attribute ending tag here, so reduce the depth
			 */
			attributeDepth--;
			/*
			 * Handle StructRef tags
			 */
			if (attributeDepth == 2 && elementStruct == null) {
				elementStruct = elementParent;
			}
			/*
			 * Handling the vsDataContainer and vendorUnitFamilyType, which were
			 * left out in startElement handling, since now we know exactly
			 * which MO Class the MO belongs to
			 */
			if (qName.equals("in:vendorUnitFamilyType")) {
				/*
				 * Since the Inventory XML contains multiple InventoryUnit tags,
				 * we'll replace them here with the "correct" type into the FDN,
				 * so ENIQ TechPack can distinguish them from each other easily.
				 */
				moClass = getData(characters);
				fdn.handle(moClass + "=" + moId, fdnDepth);
				logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
				dataMap.put(fdnIdentifier, fdn.getFdn());
			} else if (qName.equals("xn:vsDataType")) {
				//EDEAMAI - Handle tag DataType in a separate method
				handleDataTypeTag();
				
			}
			/*
			 * We have reached the end of reading, write data out.
			 */
			if (qName.endsWith(":attributes")) {
				if (qName.startsWith("in:")) {
					/*
					 * For SMO Files we can always write when in:attributes tag
					 * is found.
					 */
					if (elementTypesSup.isEmpty() || elementTypesSup.contains(elementType)) {
						//EDEAMAI - Only write to file if the node type of this data is supported.
						writeData(moClass, moId);
					} else {
						//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
						dataMap.clear();
						vectorMap.clear();
					}
				}
				/*
				 * Reset the variables
				 */
				vsDataClass = null;
				moId = null;
				collect = false;
				attributeDepth = 0;
			}
			/*
			 * If we're still collecting, put the data to the map.
			 */
			if (collect) {
				/*
				 * In case of non-struct, we just put the value into the map In
				 * case the tag exists already, we know that it's a sequence
				 * then, so we take the previous value into account
				 */
				if (elementStruct == null) {
					//EDEAMAI - We are not in a struct - handle this in separate method for code clarity:
					handleNonStruct(qName);
					
				} else {
					// If the value is StructRef, then we have to append also
					// the Struct name before the parameter
					if (qName.equals(elementStruct)) {
						/*
						 * We have now reached the end of the <struct></struct>,
						 * so we reset the elementStruct flag to null, so we can
						 * continue collection of "regular" attributes from file
						 */
						elementStruct = null;
					} else {
						/*
						 * We are still inside of <struct></struct> tag, so we
						 * have to append the values to existing value. EDEAMAI - Handle struct 
						 * in seperate method for code clarity.
						 */
						handleStruct(qName);
					}

				}
				characters = new StringBuilder();
			}
		} else {
			/*
			 * If document tag, collect data, else decrease the FDN length
			 */
			if (namespaceURI.equals("configData.xsd") || namespaceURI.endsWith("#configData")) {
				if (qName.equals("bulkCmConfigDataFile")) {
					writeData("bulkCmConfigDataFile", "none");
				}
			}
			fdnDepth--;
		}

	}

	/**
	 * Called by endElement when we're in a struct.
	 * @param qName
	 */
	private void handleStruct(String qName) {
		String key = elementStruct.split(":")[1] + structIdentifier + qName.split(":")[1];
		if (!dataMap.containsKey(key)) {
			/*
			 * Append the data
			 */
			dataMap.put(key, getData(characters));
			/*
			 * Set sequenceIndex to 0
			 */
			sequenceIndex = 0;
		} else {
			/*
			 * Initialize Vector dataHolder if not already
			 * initialized
			 */
			HashMap<String, String> valueHolder = vectorMap.get(String.valueOf(sequenceIndex));
			/*
			 * On first index, we have to copy the previous
			 * value from datamap to vector map, and then
			 * continue as normal
			 */
			if (sequenceIndex == 0) {
				/*
				 * Get previous value from from dataMap
				 */

				String previousValue = dataMap.get(key);
				/*
				 * If there is no valueHolder, create one
				 */
				if (valueHolder == null){
					valueHolder = new HashMap<String, String>();
				}
				/*
				 * Put the previous value into map
				 */
				valueHolder.put(key, previousValue);
				/*
				 * Put the valueHolder into vectorMap
				 */
				vectorMap.put(String.valueOf(sequenceIndex),valueHolder);
				sequenceIndex++;
				valueHolder = vectorMap.get(String.valueOf(sequenceIndex));
			}
			/*
			 * If there is no valueHolder, create one
			 */
			if (valueHolder == null){
				valueHolder = new HashMap<String, String>();
			}
			/*
			 * Put the value into map
			 */
			valueHolder.put(key, getData(characters));
			/*
			 * Append data to valueHolder
			 */
			vectorMap.put(String.valueOf(sequenceIndex), valueHolder);

			sequenceIndex++;
		}
	}

	/**
	 * Called by endElement when handling attibute that are not inside a struct.
	 * @param qName
	 */
	private void handleNonStruct(String qName) {
		String key = qName.split(":")[1];

		if (!dataMap.containsKey(key) && !key.equals(vsDataClass)) {
			/*
			 * Append the data
			 */
			dataMap.put(key, getData(characters));
			/*
			 * Set sequenceIndex to 0
			 */
			sequenceIndex = 0;
		} else if (!key.equals(vsDataClass)) {
			/*
			 * Initialize Vector dataHolder if not already
			 * initialized
			 */
			HashMap<String, String> valueHolder = vectorMap.get(String.valueOf(sequenceIndex));
			/*
			 * On first index, we have to copy the previous value
			 * from datamap to vector map, and then continue as
			 * normal
			 */
			if (sequenceIndex == 0) {
				/*
				 * Get previous value from from dataMap
				 */
				String previousValue = dataMap.get(key);
				/*
				 * If there is no valueHolder, create one
				 */
				if (valueHolder == null) {
					valueHolder = new HashMap<String, String>();
				}
				/*
				 * Put the previous value into map
				 */
				valueHolder.put(key, previousValue);
				/*
				 * Put the valueHolder into vectorMap
				 */
				vectorMap.put(String.valueOf(sequenceIndex),valueHolder);
				sequenceIndex++;
				valueHolder = vectorMap.get(String.valueOf(sequenceIndex));
			}
			/*
			 * If there is no valueHolder, create one
			 */
			if (valueHolder == null) {
				valueHolder = new HashMap<String, String>();
			}
			/*
			 * Put the value into map
			 */
			valueHolder.put(key, getData(characters));
			/*
			 * Append data to valueHolder
			 */
			vectorMap.put(String.valueOf(sequenceIndex), valueHolder);

			sequenceIndex++;
		}
	}

	/**
	 * Called by endElement when handling the "xn:vsDataType" tag
	 */
	private void handleDataTypeTag() {
		/*
		 * Create a marker
		 */
		boolean marker = false;
		/*
		 * First, remove the vsData from the string
		 */
		vsDataClass = getData(characters).replace("vsData", "");
		/*
		 * Check if the DataContainer following the parent is the same vsData
		 */
		if (!parentMoClass.equals(vsDataClass) || !parentMoId.equals(moId)) {
			/*
			 * If the parentMoClass is not the same as vsDataClass, or the MOs have different id, we write
			 */
			marker = true;
		}
		/*
		 * If marker was set, write data
		 */
		if (marker) {
			/*
			 * Write the data to the file
			 */
			if (!dataMap.isEmpty()){ 
				if ( elementTypesSup.isEmpty() || elementTypesSup.contains(elementType) ) {
					//EDEAMAI - Only write to file if the node type of this data is supported.
					writeData(parentMoClass, parentMoId);
				} else {
					//EDEAMAI - The node type is not supported, will not write data to file. Clearing its data.
					dataMap.clear();
					vectorMap.clear();
				}
			} 
			/*
			 * Correct the FDN
			 */
			fdn.handle(characters + "=" + moId, fdnDepth);
			/*
			 * Check do we have to remove the vsData from the MO name?
			 */
			/*
			 * Set the MO into correct value, so when writing the
			 * attributes they go to correct measurement type
			 */
			parentMoClass = vsDataClass;
			parentMoId = moId;
			logger.log(Level.FINEST, "Constructed FDN " + fdn.getFdn());
		}
	}

	/**
	 * Reads the character data between tags, e.g. <tag>character data</tag>
	 * 
	 */
	public void characters(char buf[], int offset, int len) throws SAXException {
		/*
		 * Append the corrected data to characters
		 */
		characters.append(new String(buf, offset, len).trim());
	}

	/**
	 * Initializes the Parser
	 * 
	 * @param main
	 *            - The Main Parser Object
	 * @param techPack
	 *            - The Target Techpack the parsing is done for
	 * @param setType
	 *            - The type of the Set
	 * @param setName
	 *            - The name of the Set
	 * @param workerName
	 *            - The name of the worker assigned for this parsing action
	 */
	@Override
	public void init(Main main, String techPack, String setType, String setName, String workerName) {
		this.mainParser = main;
		this.techPack = techPack;
		this.setType = setType;
		this.setName = setName;
		this.workerName = workerName;
		logger = Logger.getLogger("etl." + techPack + "." + setType + "." + setName + ".parser.XML." + workerName);
		status = 1;
	}

	/**
	 * Parses the XML file
	 * 
	 * 
	 * @param sf
	 *            - The SourceFile provided by the Main Parser
	 * @param techPack
	 *            - The Target Techpack the parsing is done for
	 * @param setType
	 *            - The type of the Set
	 * @param setName
	 *            - The name of the Set
	 */
	@Override
	public void parse(SourceFile sf, String techPack, String setType, String setName) throws Exception {
		logger.finest("Reading Interface configuration...");
		
		/*
		 * EDEAMAI - Get interface properties and set parameters in a separate method for code clarity.
		 */
		getAndSetParameters(sf);
		
		/*
		 * Initialize variables
		 */
		this.techPack = techPack;
		this.setType = setType;
		this.setName = setName;
		sourceFile = sf;
		fdn = new Fdn(removeRootMoR, removeVsData);
		dataMap = new HashMap<String, String>();
		docDataMap = new HashMap<String, String>();
		/*
		 * Set the type to OSSRC immediately
		 */
		vectorMap = new LinkedHashMap<String, HashMap<String, String>>();
		openFiles = new HashMap<String, MeasurementFile>();
		vectorListSet = new HashMap<String, List<String>>();
		fdn.reset();
		characters = new StringBuilder();
		moId = null;
		moClass = null;
		parentMoClass = null;
		parentMoId = null;
		fdnDepth = 0;
		attributeDepth = 0;
		collect = false;
		isStruct = false;
		elementParent = null;
		elementStart = null;
		elementStruct = null;
		elementEnd = null;
		/*
		 * Create Parser
		 */
		logger.log(Level.FINEST, "Creating SAXParser...");
		try {
			SAXParserFactory factory = SAXParserFactory.newInstance();
			factory.setNamespaceAware(true);
			factory.setValidating(true);
			SAXParser parser = factory.newSAXParser();
			logger.log(Level.FINE, "Initilizing parsing...");
			parser.parse(sf.getFileInputStream(), this);
		} catch (SAXException e) {
			
			e.printStackTrace();
			logger.log(Level.SEVERE, "Unable to parse the XML file,", e);
		} catch (IOException e) {

			e.printStackTrace();
			logger.log(Level.SEVERE, "Unable to read the XML file,", e);
		} catch (ParserConfigurationException e) {

			e.printStackTrace();
			logger.log(Level.SEVERE, "ParserConfigurationException was thrown,", e);

		}
		logger.log(Level.FINE, "Parse finished.");
	}

	/**
	 * Gets interface properties and uses then to set parameters and maps
	 * @param sf
	 */
	private void getAndSetParameters(SourceFile sf) throws Exception{
		/*
		 * Get Interface Parameters
		 */
		fdnIdentifier = sf.getProperty("BCDParser.fdnIdentifier", "FDN");
		snIdentifier = sf.getProperty("BCDParser.snIdentifier", "SN");
		moidIdentifier = sf.getProperty("BCDParser.moidIdentifier", "MOID");
		sequenceSeparator = sf.getProperty("BCDParser.sequenceSeparator", ";");
		structIdentifier = sf.getProperty("BCDParser.structIdentifier", "_");
		removeRootMoR = Boolean.parseBoolean(sf.getProperty("BCDParser.removeRootMoR", "true"));
		removeVsData = Boolean.parseBoolean(sf.getProperty("BCDParser.removeVsData", "true"));
		sequenceIdentifier = sf.getProperty("BCDParser.sequenceIdentifier","DCVECTOR_INDEX");
		aomIdentifier = sf.getProperty("BCDParser.aomIdentifier", "AOM");
		cuIdentifier = sf.getProperty("BCDParser.cuIdentifier", "CU");
		releaseIdentifier = sf.getProperty("BCDParser.releaseIdentifier","DC_RELEASE");
		dateTimeIdentifier = sf.getProperty("BCDParser.dateTimeIdentifier","DATETIME_ID");
		timezoneIdentifier = sf.getProperty("BCDParser.timezoneIdentifier","DC_TIMEZONE");
		timelevelIdentifier = sf.getProperty("BCDParser.timelevelIdentifier","TIMELEVEL");
		periodDurationIdentifier = sf.getProperty("BCDParser.periodDurationIdentifier", "PERIOD_DURATION");
		ossIdIdentifier = sf.getProperty("BCDParser.ossIdIdentifier", "OSS_ID");
		sourceIdentifier = sf.getProperty("BCDParser.sourceIdentifier","DC_SOURCE");
		dirnameIdentifier = sf.getProperty("BCDParser.sourceIdentifier","DIRNAME");
		filenameIdentifier = sf.getProperty("BCDParser.sourceIdentifier","FILENAME");
		jvmTimezoneIdentifier = sf.getProperty("BCDParser.sourceIdentifier","JVM_TIMEZONE");
		timelevel = sf.getProperty("BCDParser.timelevel", "24H");
		periodDuration = sf.getProperty("BCDParser.periodDuration", "1440");
		/*
		 * Get file transformation parameters, and read the variables in the
		 * start rather that transforming them for every single measurement type
		 */
		aomPattern = sf.getProperty("BCDParser.aomPattern", null);
		if (aomPattern != null) {
			aom = transformFileVariables("aomPattern", sf.getName(), aomPattern);
		} else {
			aom = null;
		}
		cuPattern = sf.getProperty("BCDParser.cuPattern", null);
		if (cuPattern != null) {
			cu = transformFileVariables("cuPattern", sf.getName(), cuPattern);
		} else {
			cu = null;
		}
		releasePattern = sf.getProperty("BCDParser.releasePattern", null);
		if (releasePattern != null) {
			release = transformFileVariables("releasefPattern", sf.getName(),
					releasePattern);
		} else {
			release = null;
		}
		hostnamePattern = sf.getProperty("BCDParser.hostnamePattern", null);  //Never used.
		if (hostnamePattern != null) {
			hostname = transformFileVariables("hostnamePattern", sf.getName(),
					hostnamePattern);
		} else {
			hostname = null;
		}
		datetimeIdPattern = sf.getProperty("BCDParser.datetimeIdPattern", null);
		if (datetimeIdPattern != null) {
			datetimeId = transformFileVariables("datetimeIdPattern", sf
					.getName(), datetimeIdPattern);
		} else {
			datetimeId = null;
		}
		timeZonePattern = sf.getProperty("BCDParser.timeZonePattern", null);
		if (timeZonePattern != null) {
			timeZone = transformFileVariables("timeZonePattern", sf.getName(),
					timeZonePattern);
		} else {
			timeZone = null;
		}
		ossIdPattern = sf.getProperty("BCDParser.ossIdPattern", ".+/(.+)/.+/.+");
		if (ossIdPattern != null) {
			ossId = transformFileVariables("ossIdPattern", sf.getDir(),
					ossIdPattern);
		} else {
			ossIdPattern = null;
		}

		/*
		 * EDEAMAI - Get the network element types to support.
		 */
		final StringTokenizer strToken1 = new StringTokenizer(sf.getProperty("BCDParser.elementTypesSupported", ""), ",");
		while (strToken1.hasMoreTokens()){
			String nodeType = strToken1.nextToken();
			elementTypesSup.add(nodeType); //Put the node types (if any) into an ArrayList.
			logger.info("Supporting Network Element: "+nodeType);
		}
		if(elementTypesSup.size()>0) {
			if (!elementTypesSup.contains(OSSRC)){
				//EDEAMAI - If there are any node types specified by interface then ensure OSSRC gets included. 
				elementTypesSup.add(OSSRC);
				logger.info("Supporting Network Element: OSSRC");
			}
		} else {
			logger.fine("No restrictions on Network Element type imposed by interface");
		}
		//EDEAMAI - But if there are no node types specified, then the ArrayList is left empty - which will be taken as indication 
		//that ALL node types are supported (i.e. parser will not impose any node type restriction - tech pack will be the only limiter).
		
		/*
		 * EDEAMAI - Make a default map of element types to FDN patterns.
		 */
		elementFDNMap.put(RNC, Pattern.compile(rncPattern));
		elementFDNMap.put(TDRNC, Pattern.compile(rncPattern));
		elementFDNMap.put(RBS, Pattern.compile(rbsPattern));
		elementFDNMap.put(TDRBS, Pattern.compile(rbsPattern));
		elementFDNMap.put("other", Pattern.compile(otherPattern)); //EDEAMAI - Let us hope that in the future there will never be a node type called "other"...
		/*
		 * EDEAMAI - Over write, or add to, the entries in default map with patterns configured in interface properties.
		 */
		final StringTokenizer strToken2 = new StringTokenizer(sf.getProperty("BCDParser.elementTypesFDNProvided", ""), ",");
		while (strToken2.hasMoreTokens()){
			final String nodeType = strToken2.nextToken();
			final String fdnPattern = sf.getProperty("BCDParser.FDNPattern."+nodeType, null);
			if (null==fdnPattern){
				//EDEAMAI - There has to be a FDN pattern configured for every node type listed in BCDParser.elementTypesFDNProvided
				throw new Exception("There is no FDN pattern configured in interface for: "+nodeType+". Please configure one, or remove "+nodeType
						+" from property BCDParser.elementTypesFDNProvided");
			}
			elementFDNMap.put(nodeType, Pattern.compile(fdnPattern));
		}
		
		//EDEAMAI - NB: it is NOT NECESSARY that the list of supported node types (elementTypesSup) be consistent with 
		//the node types in the FDN map (elementFDNMap). These 2 lists are independent. 
		//EDEAMAI - NB: elementTypesSup controls what node types get supported. It is an optional list and would be a subset of 
		//nodes supported by the tech pack. If it is empty then all nodes types will be supported (i.e. all node types 
		//that are supported by tech pack). 
		//EDEAMAI - NB: elementFDNMap NEVER controls what node types are supported. It's just a mapping btwn. node types and FDN patterns.
	}

	/**
	 * Returns the status of parsing to the Main Parser.
	 * 
	 */
	@Override
	public int status() {
		return status;
	}

	/**
	 * Starts the BCDParser Thread and parse() action
	 */
	@Override
	public void run() {
		try {
			this.status = 2;
			SourceFile sf = null;
			while ((sf = mainParser.nextSourceFile()) != null) {
				try {
					mainParser.preParse(sf);
					parse(sf, techPack, setType, setName);
					mainParser.postParse(sf);
				} catch (Exception e) {
					mainParser.errorParse(e, sf);
				} finally {
					mainParser.finallyParse(sf);
				}
			}
		} catch (Exception e) {
			// Exception catched at top level. No good.
			logger.log(Level.WARNING, "Worker parser failed to exception", e);
		} finally {
			this.status = 3;
		}

	}

	/**
	 * Checks if the Measurement File for the ManagedObject is already open and
	 * returns it. If Measurement File does not exist, a new file will be
	 * created and stored in cache.
	 * 
	 * @return MeasurementFile - where the parsed data will be written
	 * 
	 * @param String
	 *            mo - type of ManagedObject
	 */
	private MeasurementFile getMFile(String mo) {
		try {
			MeasurementFile msf = (MeasurementFile) openFiles.get(mo);
			if (msf == null) {
				msf = Main.createMeasurementFile(sourceFile, mo, techPack, setType, setName, this.workerName, logger);
								
				openFiles.put(mo, msf);
				
				if (vectorListSet.get(mo) == null){
				  String ifName = sourceFile.getProperty("interfaceName");
				  List<String> vectorNames = createVectorList(mo, ifName);
				  if (vectorNames != null){
				    vectorListSet.put(mo, vectorNames);
				  }
				}
			}
			return msf;
		} catch (Exception e) {
			logger.log(Level.WARNING, "Unable to create measurement file", e);
			return null;
		}
	}
	
	private List<String> createVectorList (final String tagId, final String ifName){
		List<String> vectorList = new ArrayList<String> ();
		final DataFormatCache dfc = DataFormatCache.getCache();
		final DFormat df = dfc.getFormatWithTagID(ifName, tagId);
		if (df == null) {
			return  null;
		}
    
		final List<DItem> dItemList = df.getDitems();
		for (DItem di : dItemList){
			String pi = di.getProcessInstruction();
			if (pi != null && pi.contains("VECTOR")) {
				vectorList.add(di.getDataName());
			}
		}
		return vectorList;
	}
	
	/**
	 * Returns the data of XML Elements, e.g. <tag>data</tag>.
	 * 
	 * Affecting Interface Properties:
	 * 
	 * 
	 * @return String - The formatted value of xml tags
	 * 
	 * @param StringBuilder
	 *            characters - the parsed XML characters
	 */
	private String getData(StringBuilder characters) {
		/*
		 * Get the characters data and trim it
		 */
		String data = characters.toString().trim();
		/*
		 * Remove all vsData from data, if flag is set on
		 */
		if (removeVsData) {
			data = data.replaceAll("vsData", "");
		}
		/*
		 * If the removeR is defined, search for the SubNetwork=*******_R, from
		 * the data. It has to be removed, so that the FDN matches the one in
		 * statistics
		 */
		if (removeRootMoR && data.startsWith("SubNetwork=")) {
			Pattern pattern = Pattern.compile("^SubNetwork=(.+_R),.*");
			Matcher matcher = pattern.matcher(data);
			/*
			 * Do we have FDN?
			 */
			if (matcher.matches()) {
				/*
				 * Yes we do, do we have _R in the end of RootMO
				 */
				String root = matcher.group(1);
				/*
				 * Remove _R
				 */
				String newRoot = "SubNetwork=" + root.substring(0, root.length() - 2) + ",";
				data = data.replaceAll("^SubNetwork=" + root + ",", newRoot);
			}
		}
		return data;
	}
}
